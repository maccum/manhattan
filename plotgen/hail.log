2018-06-29 18:02:10 SparkContext: INFO: Running Spark version 2.2.0
2018-06-29 18:02:10 NativeCodeLoader: WARN: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-06-29 18:02:11 SparkContext: INFO: Submitted application: Hail
2018-06-29 18:02:11 SparkContext: INFO: Spark configuration:
spark.app.name=Hail
spark.driver.extraClassPath=/Users/maccum/hail/build/libs/hail-all-spark.jar
spark.driver.memory=8G
spark.executor.extraClassPath=/Users/maccum/hail/build/libs/hail-all-spark.jar
spark.hadoop.io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,is.hail.io.compress.BGzipCodec,org.apache.hadoop.io.compress.GzipCodec
spark.hadoop.mapreduce.input.fileinputformat.split.minsize=1048576
spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator
spark.logConf=true
spark.master=local[*]
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.submit.deployMode=client
spark.ui.showConsoleProgress=false
2018-06-29 18:02:11 SecurityManager: INFO: Changing view acls to: maccum
2018-06-29 18:02:11 SecurityManager: INFO: Changing modify acls to: maccum
2018-06-29 18:02:11 SecurityManager: INFO: Changing view acls groups to: 
2018-06-29 18:02:11 SecurityManager: INFO: Changing modify acls groups to: 
2018-06-29 18:02:11 SecurityManager: INFO: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(maccum); groups with view permissions: Set(); users  with modify permissions: Set(maccum); groups with modify permissions: Set()
2018-06-29 18:02:11 Utils: INFO: Successfully started service 'sparkDriver' on port 62556.
2018-06-29 18:02:11 SparkEnv: INFO: Registering MapOutputTracker
2018-06-29 18:02:11 SparkEnv: INFO: Registering BlockManagerMaster
2018-06-29 18:02:11 BlockManagerMasterEndpoint: INFO: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-06-29 18:02:11 BlockManagerMasterEndpoint: INFO: BlockManagerMasterEndpoint up
2018-06-29 18:02:11 DiskBlockManager: INFO: Created local directory at /private/var/folders/sb/_knnc68j2tx24w7pqktd64pn5d__pn/T/blockmgr-6f8ee2d5-fbdd-4b57-891b-b23dedd217ff
2018-06-29 18:02:11 MemoryStore: INFO: MemoryStore started with capacity 4.1 GB
2018-06-29 18:02:11 SparkEnv: INFO: Registering OutputCommitCoordinator
2018-06-29 18:02:12 log: INFO: Logging initialized @2642ms
2018-06-29 18:02:12 Server: INFO: jetty-9.3.z-SNAPSHOT
2018-06-29 18:02:12 Server: INFO: Started @2722ms
2018-06-29 18:02:12 AbstractConnector: INFO: Started ServerConnector@193dc97e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-06-29 18:02:12 Utils: INFO: Successfully started service 'SparkUI' on port 4040.
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@67b33a00{/jobs,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1150bec7{/jobs/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@44f32c2e{/jobs/job,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@22c19223{/jobs/job/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2e7179b3{/stages,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@54d6f6a4{/stages/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7c8c7457{/stages/stage,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4b407557{/stages/stage/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2dcab9af{/stages/pool,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3d2b9372{/stages/pool/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@32a9d2b{/storage,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5a9800fd{/storage/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5ca944a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@30344f9b{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@47eb3475{/environment,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@764ddd33{/environment/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@3781593c{/executors,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@73832786{/executors/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@5bf3a4bc{/executors/threadDump,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@24508e67{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@365d4ee4{/static,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@479b0284{/,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@1d633fd7{/api,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6eeb8815{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@229c0d0c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 SparkUI: INFO: Bound SparkUI to 0.0.0.0, and started at http://10.1.7.107:4040
2018-06-29 18:02:12 Executor: INFO: Starting executor ID driver on host localhost
2018-06-29 18:02:12 Utils: INFO: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62557.
2018-06-29 18:02:12 NettyBlockTransferService: INFO: Server created on 10.1.7.107:62557
2018-06-29 18:02:12 BlockManager: INFO: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-06-29 18:02:12 BlockManagerMaster: INFO: Registering BlockManager BlockManagerId(driver, 10.1.7.107, 62557, None)
2018-06-29 18:02:12 BlockManagerMasterEndpoint: INFO: Registering block manager 10.1.7.107:62557 with 4.1 GB RAM, BlockManagerId(driver, 10.1.7.107, 62557, None)
2018-06-29 18:02:12 BlockManagerMaster: INFO: Registered BlockManager BlockManagerId(driver, 10.1.7.107, 62557, None)
2018-06-29 18:02:12 BlockManager: INFO: Initialized BlockManager: BlockManagerId(driver, 10.1.7.107, 62557, None)
2018-06-29 18:02:12 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@60f2558a{/metrics/json,null,AVAILABLE,@Spark}
2018-06-29 18:02:12 Hail: INFO: SparkUI: http://10.1.7.107:4040
2018-06-29 18:02:12 Hail: INFO: Running Hail version devel-47a3ae6598a3
2018-06-29 18:02:13 root: INFO: in Table.value: pre-opt:
(TableUnkey
  (TableRange))
2018-06-29 18:02:13 root: INFO: in Table.value: post-opt:
(TableUnkey
  (TableRange))
2018-06-29 18:02:13 root: INFO: is/hail/codegen/generated/C0.<init> instruction count: 3
2018-06-29 18:02:13 root: INFO: is/hail/codegen/generated/C0.apply instruction count: 61
2018-06-29 18:02:13 root: INFO: is/hail/codegen/generated/C0.apply instruction count: 12
2018-06-29 18:02:13 root: INFO: in Table.value: pre-opt:
(TableMapRows
  (TableMapGlobals
    (TableMapRows
      (TableMapGlobals
        (TableLiteral)
        (InsertFields
          (Ref Struct{} global)
          (__uid_1
            (GetField __uid_1
              (Ref Struct{__uid_1:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} value)))))
      (MakeStruct
        (__uid_2
          (GetField __uid_1
            (Ref Struct{__uid_1:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} global)))))
    (MakeStruct))
  (MakeStruct
    (__uid_2
      (GetField __uid_2
        (Ref Struct{__uid_2:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} row)))))
2018-06-29 18:02:13 root: INFO: in Table.value: post-opt:
(TableMapRows
  (TableMapGlobals
    (TableMapRows
      (TableMapGlobals
        (TableLiteral)
        (InsertFields
          (Ref Struct{} global)
          (__uid_1
            (GetField __uid_1
              (Ref Struct{__uid_1:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} value)))))
      (MakeStruct
        (__uid_2
          (GetField __uid_1
            (Ref Struct{__uid_1:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} global)))))
    (MakeStruct))
  (MakeStruct
    (__uid_2
      (GetField __uid_2
        (Ref Struct{__uid_2:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} row)))))
2018-06-29 18:02:13 root: INFO: is/hail/codegen/generated/C1.<init> instruction count: 3
2018-06-29 18:02:13 root: INFO: is/hail/codegen/generated/C1.apply instruction count: 88
2018-06-29 18:02:13 root: INFO: is/hail/codegen/generated/C1.apply instruction count: 22
2018-06-29 18:02:13 root: INFO: is/hail/codegen/generated/C2.<init> instruction count: 3
2018-06-29 18:02:13 root: INFO: is/hail/codegen/generated/C2.apply instruction count: 76
2018-06-29 18:02:13 root: INFO: is/hail/codegen/generated/C2.apply instruction count: 22
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 1784.0 B, free 4.1 GB)
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 359.0 B, free 4.1 GB)
2018-06-29 18:02:14 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on 10.1.7.107:62557 (size: 359.0 B, free: 4.1 GB)
2018-06-29 18:02:14 SparkContext: INFO: Created broadcast 0 from broadcast at BroadcastValue.scala:14
2018-06-29 18:02:14 root: INFO: is/hail/codegen/generated/C3.<init> instruction count: 3
2018-06-29 18:02:14 root: INFO: is/hail/codegen/generated/C3.apply instruction count: 23
2018-06-29 18:02:14 root: INFO: is/hail/codegen/generated/C3.apply instruction count: 22
2018-06-29 18:02:14 root: INFO: is/hail/codegen/generated/C4.<init> instruction count: 3
2018-06-29 18:02:14 root: INFO: is/hail/codegen/generated/C4.apply instruction count: 76
2018-06-29 18:02:14 root: INFO: is/hail/codegen/generated/C4.apply instruction count: 22
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 56.0 B, free 4.1 GB)
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 120.0 B, free 4.1 GB)
2018-06-29 18:02:14 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on 10.1.7.107:62557 (size: 120.0 B, free: 4.1 GB)
2018-06-29 18:02:14 SparkContext: INFO: Created broadcast 1 from broadcast at BroadcastValue.scala:14
2018-06-29 18:02:14 SparkContext: INFO: Starting job: collect at Table.scala:810
2018-06-29 18:02:14 DAGScheduler: INFO: Got job 0 (collect at Table.scala:810) with 1 output partitions
2018-06-29 18:02:14 DAGScheduler: INFO: Final stage: ResultStage 0 (collect at Table.scala:810)
2018-06-29 18:02:14 DAGScheduler: INFO: Parents of final stage: List()
2018-06-29 18:02:14 DAGScheduler: INFO: Missing parents: List()
2018-06-29 18:02:14 DAGScheduler: INFO: Submitting ResultStage 0 (MapPartitionsRDD[11] at mapPartitions at ContextRDD.scala:137), which has no missing parents
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 14.7 KB, free 4.1 GB)
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.1 KB, free 4.1 GB)
2018-06-29 18:02:14 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on 10.1.7.107:62557 (size: 7.1 KB, free: 4.1 GB)
2018-06-29 18:02:14 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-06-29 18:02:14 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[11] at mapPartitions at ContextRDD.scala:137) (first 15 tasks are for partitions Vector(0))
2018-06-29 18:02:14 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2018-06-29 18:02:14 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4713 bytes)
2018-06-29 18:02:14 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2018-06-29 18:02:14 MemoryStore: INFO: Block rdd_4_0 stored as values in memory (estimated size 56.0 B, free 4.1 GB)
2018-06-29 18:02:14 BlockManagerInfo: INFO: Added rdd_4_0 in memory on 10.1.7.107:62557 (size: 56.0 B, free: 4.1 GB)
2018-06-29 18:02:14 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1795 bytes result sent to driver
2018-06-29 18:02:14 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 165 ms on localhost (executor driver) (1/1)
2018-06-29 18:02:14 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-06-29 18:02:14 DAGScheduler: INFO: ResultStage 0 (collect at Table.scala:810) finished in 0.185 s
2018-06-29 18:02:14 DAGScheduler: INFO: Job 0 finished: collect at Table.scala:810, took 0.271610 s
2018-06-29 18:02:14 root: INFO: interpret: PRE-OPT
(TableWrite plotgen/test/test_resources/random_table.ht overwrite
  (TableParallelize))
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 237.1 KB, free 4.1 GB)
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.0 KB, free 4.1 GB)
2018-06-29 18:02:14 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on 10.1.7.107:62557 (size: 23.0 KB, free: 4.1 GB)
2018-06-29 18:02:14 SparkContext: INFO: Created broadcast 3 from broadcast at RichContextRDD.scala:20
2018-06-29 18:02:14 SparkContext: INFO: Starting job: collect at ContextRDD.scala:143
2018-06-29 18:02:14 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:143) with 2 output partitions
2018-06-29 18:02:14 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:143)
2018-06-29 18:02:14 DAGScheduler: INFO: Parents of final stage: List()
2018-06-29 18:02:14 DAGScheduler: INFO: Missing parents: List()
2018-06-29 18:02:14 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[16] at mapPartitions at ContextRDD.scala:137), which has no missing parents
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_4 stored as values in memory (estimated size 7.2 KB, free 4.1 GB)
2018-06-29 18:02:14 MemoryStore: INFO: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.1 KB, free 4.1 GB)
2018-06-29 18:02:14 BlockManagerInfo: INFO: Added broadcast_4_piece0 in memory on 10.1.7.107:62557 (size: 4.1 KB, free: 4.1 GB)
2018-06-29 18:02:14 SparkContext: INFO: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-06-29 18:02:14 DAGScheduler: INFO: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[16] at mapPartitions at ContextRDD.scala:137) (first 15 tasks are for partitions Vector(0, 1))
2018-06-29 18:02:14 TaskSchedulerImpl: INFO: Adding task set 1.0 with 2 tasks
2018-06-29 18:02:14 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes)
2018-06-29 18:02:14 TaskSetManager: INFO: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 4988 bytes)
2018-06-29 18:02:14 Executor: INFO: Running task 1.0 in stage 1.0 (TID 2)
2018-06-29 18:02:14 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2018-06-29 18:02:14 Executor: INFO: Finished task 1.0 in stage 1.0 (TID 2). 808 bytes result sent to driver
2018-06-29 18:02:14 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 808 bytes result sent to driver
2018-06-29 18:02:14 TaskSetManager: INFO: Finished task 1.0 in stage 1.0 (TID 2) in 44 ms on localhost (executor driver) (1/2)
2018-06-29 18:02:14 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 52 ms on localhost (executor driver) (2/2)
2018-06-29 18:02:14 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-06-29 18:02:14 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:143) finished in 0.053 s
2018-06-29 18:02:14 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:143, took 0.062148 s
2018-06-29 18:02:14 Hail: INFO: wrote 10 items in 2 partitions
2018-06-29 18:02:14 CodecPool: INFO: Got brand-new decompressor [.gz]
2018-06-29 18:02:15 BlockManagerInfo: INFO: Removed broadcast_3_piece0 on 10.1.7.107:62557 in memory (size: 23.0 KB, free: 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Removed broadcast_4_piece0 on 10.1.7.107:62557 in memory (size: 4.1 KB, free: 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on 10.1.7.107:62557 in memory (size: 7.1 KB, free: 4.1 GB)
2018-06-29 18:02:15 root: INFO: interpret: PRE-OPT
(TableAggregate
  (TableRead plotgen/test/test_resources/random_table.ht)
  (ApplyAggOp (Max Int64 () None ())
    (SeqOp (Max Int64 () None ())
      (Let __uid_3
        (Ref Struct{global_position:Int64,neg_log_pval:Float64,color:String} row)
        (GetField global_position
          (Ref Struct{global_position:Int64,neg_log_pval:Float64,color:String} row)))
      (I32 0)
      ())
    ()
    None))
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C5.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C5.apply instruction count: 18
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C5.apply instruction count: 7
2018-06-29 18:02:15 root: INFO: initop (Begin)
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C6.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C6.apply instruction count: 15
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C6.apply instruction count: 16
2018-06-29 18:02:15 root: INFO: seqop (Begin
  (SeqOp (Max Int64 () None ())
    (GetField global_position
      (Ref Struct{global_position:Int64} row))
    (I32 0)
    ()))
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C7.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C7.apply instruction count: 78
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C7.apply instruction count: 22
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C8.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C8.apply instruction count: 76
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C8.apply instruction count: 22
2018-06-29 18:02:15 CodecPool: INFO: Got brand-new decompressor [.gz]
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C9.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C9.apply instruction count: 18
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C9.apply instruction count: 12
2018-06-29 18:02:15 CodecPool: INFO: Got brand-new decompressor [.gz]
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C10.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C10.apply instruction count: 91
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C10.apply instruction count: 12
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_5 stored as values in memory (estimated size 237.1 KB, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_5_piece0 stored as bytes in memory (estimated size 23.0 KB, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_5_piece0 in memory on 10.1.7.107:62557 (size: 23.0 KB, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 5 from broadcast at HailContext.scala:561
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_6 stored as values in memory (estimated size 56.0 B, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_6_piece0 stored as bytes in memory (estimated size 120.0 B, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_6_piece0 in memory on 10.1.7.107:62557 (size: 120.0 B, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 6 from broadcast at BroadcastValue.scala:14
2018-06-29 18:02:15 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:191
2018-06-29 18:02:15 DAGScheduler: INFO: Got job 2 (runJob at ContextRDD.scala:191) with 2 output partitions
2018-06-29 18:02:15 DAGScheduler: INFO: Final stage: ResultStage 2 (runJob at ContextRDD.scala:191)
2018-06-29 18:02:15 DAGScheduler: INFO: Parents of final stage: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Missing parents: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting ResultStage 2 (MapPartitionsRDD[19] at mapPartitions at ContextRDD.scala:290), which has no missing parents
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_7 stored as values in memory (estimated size 9.0 KB, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.3 KB, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_7_piece0 in memory on 10.1.7.107:62557 (size: 5.3 KB, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[19] at mapPartitions at ContextRDD.scala:290) (first 15 tasks are for partitions Vector(0, 1))
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Adding task set 2.0 with 2 tasks
2018-06-29 18:02:15 TaskSetManager: INFO: Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4655 bytes)
2018-06-29 18:02:15 TaskSetManager: INFO: Starting task 1.0 in stage 2.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 4655 bytes)
2018-06-29 18:02:15 Executor: INFO: Running task 1.0 in stage 2.0 (TID 4)
2018-06-29 18:02:15 Executor: INFO: Running task 0.0 in stage 2.0 (TID 3)
2018-06-29 18:02:15 Executor: INFO: Finished task 1.0 in stage 2.0 (TID 4). 876 bytes result sent to driver
2018-06-29 18:02:15 Executor: INFO: Finished task 0.0 in stage 2.0 (TID 3). 876 bytes result sent to driver
2018-06-29 18:02:15 TaskSetManager: INFO: Finished task 0.0 in stage 2.0 (TID 3) in 21 ms on localhost (executor driver) (1/2)
2018-06-29 18:02:15 TaskSetManager: INFO: Finished task 1.0 in stage 2.0 (TID 4) in 21 ms on localhost (executor driver) (2/2)
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-06-29 18:02:15 DAGScheduler: INFO: ResultStage 2 (runJob at ContextRDD.scala:191) finished in 0.024 s
2018-06-29 18:02:15 DAGScheduler: INFO: Job 2 finished: runJob at ContextRDD.scala:191, took 0.038941 s
2018-06-29 18:02:15 root: INFO: interpret: PRE-OPT
(TableAggregate
  (TableRead plotgen/test/test_resources/random_table.ht)
  (ApplyAggOp (Max Float64 () None ())
    (SeqOp (Max Float64 () None ())
      (Let __uid_4
        (Ref Struct{global_position:Int64,neg_log_pval:Float64,color:String} row)
        (GetField neg_log_pval
          (Ref Struct{global_position:Int64,neg_log_pval:Float64,color:String} row)))
      (I32 0)
      ())
    ()
    None))
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C11.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C11.apply instruction count: 18
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C11.apply instruction count: 7
2018-06-29 18:02:15 root: INFO: initop (Begin)
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C12.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C12.apply instruction count: 15
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C12.apply instruction count: 16
2018-06-29 18:02:15 root: INFO: seqop (Begin
  (SeqOp (Max Float64 () None ())
    (GetField neg_log_pval
      (Ref Struct{neg_log_pval:Float64} row))
    (I32 0)
    ()))
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C13.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C13.apply instruction count: 78
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C13.apply instruction count: 22
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C14.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C14.apply instruction count: 76
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C14.apply instruction count: 22
2018-06-29 18:02:15 CodecPool: INFO: Got brand-new decompressor [.gz]
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C15.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C15.apply instruction count: 18
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C15.apply instruction count: 12
2018-06-29 18:02:15 CodecPool: INFO: Got brand-new decompressor [.gz]
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C16.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C16.apply instruction count: 91
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C16.apply instruction count: 12
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_8 stored as values in memory (estimated size 237.1 KB, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.0 KB, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_8_piece0 in memory on 10.1.7.107:62557 (size: 23.0 KB, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 8 from broadcast at HailContext.scala:561
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_9 stored as values in memory (estimated size 56.0 B, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_9_piece0 stored as bytes in memory (estimated size 120.0 B, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_9_piece0 in memory on 10.1.7.107:62557 (size: 120.0 B, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 9 from broadcast at BroadcastValue.scala:14
2018-06-29 18:02:15 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:191
2018-06-29 18:02:15 DAGScheduler: INFO: Got job 3 (runJob at ContextRDD.scala:191) with 2 output partitions
2018-06-29 18:02:15 DAGScheduler: INFO: Final stage: ResultStage 3 (runJob at ContextRDD.scala:191)
2018-06-29 18:02:15 DAGScheduler: INFO: Parents of final stage: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Missing parents: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting ResultStage 3 (MapPartitionsRDD[22] at mapPartitions at ContextRDD.scala:290), which has no missing parents
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_10 stored as values in memory (estimated size 9.0 KB, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.3 KB, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_10_piece0 in memory on 10.1.7.107:62557 (size: 5.3 KB, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[22] at mapPartitions at ContextRDD.scala:290) (first 15 tasks are for partitions Vector(0, 1))
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Adding task set 3.0 with 2 tasks
2018-06-29 18:02:15 TaskSetManager: INFO: Starting task 0.0 in stage 3.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4655 bytes)
2018-06-29 18:02:15 TaskSetManager: INFO: Starting task 1.0 in stage 3.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 4655 bytes)
2018-06-29 18:02:15 Executor: INFO: Running task 1.0 in stage 3.0 (TID 6)
2018-06-29 18:02:15 Executor: INFO: Running task 0.0 in stage 3.0 (TID 5)
2018-06-29 18:02:15 Executor: INFO: Finished task 0.0 in stage 3.0 (TID 5). 884 bytes result sent to driver
2018-06-29 18:02:15 TaskSetManager: INFO: Finished task 0.0 in stage 3.0 (TID 5) in 9 ms on localhost (executor driver) (1/2)
2018-06-29 18:02:15 Executor: INFO: Finished task 1.0 in stage 3.0 (TID 6). 884 bytes result sent to driver
2018-06-29 18:02:15 TaskSetManager: INFO: Finished task 1.0 in stage 3.0 (TID 6) in 10 ms on localhost (executor driver) (2/2)
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-06-29 18:02:15 DAGScheduler: INFO: ResultStage 3 (runJob at ContextRDD.scala:191) finished in 0.011 s
2018-06-29 18:02:15 DAGScheduler: INFO: Job 3 finished: runJob at ContextRDD.scala:191, took 0.019222 s
2018-06-29 18:02:15 root: INFO: in Table.value: pre-opt:
(TableMapRows
  (TableMapGlobals
    (TableMapRows
      (TableMapGlobals
        (TableLiteral)
        (InsertFields
          (Ref Struct{} global)
          (__uid_5
            (GetField __uid_5
              (Ref Struct{__uid_5:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} value)))))
      (MakeStruct
        (__uid_6
          (GetField __uid_5
            (Ref Struct{__uid_5:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} global)))))
    (MakeStruct))
  (MakeStruct
    (__uid_6
      (GetField __uid_6
        (Ref Struct{__uid_6:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} row)))))
2018-06-29 18:02:15 root: INFO: in Table.value: post-opt:
(TableMapRows
  (TableMapGlobals
    (TableMapRows
      (TableMapGlobals
        (TableLiteral)
        (InsertFields
          (Ref Struct{} global)
          (__uid_5
            (GetField __uid_5
              (Ref Struct{__uid_5:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} value)))))
      (MakeStruct
        (__uid_6
          (GetField __uid_5
            (Ref Struct{__uid_5:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} global)))))
    (MakeStruct))
  (MakeStruct
    (__uid_6
      (GetField __uid_6
        (Ref Struct{__uid_6:Array[Struct{global_position:Int64,neg_log_pval:Float64,color:String}]} row)))))
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C17.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C17.apply instruction count: 88
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C17.apply instruction count: 22
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C18.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C18.apply instruction count: 76
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C18.apply instruction count: 22
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_11 stored as values in memory (estimated size 1176.0 B, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_11_piece0 stored as bytes in memory (estimated size 224.0 B, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_11_piece0 in memory on 10.1.7.107:62557 (size: 224.0 B, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 11 from broadcast at BroadcastValue.scala:14
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C19.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C19.apply instruction count: 23
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C19.apply instruction count: 22
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C20.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C20.apply instruction count: 76
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C20.apply instruction count: 22
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_12 stored as values in memory (estimated size 56.0 B, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_12_piece0 stored as bytes in memory (estimated size 120.0 B, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_12_piece0 in memory on 10.1.7.107:62557 (size: 120.0 B, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 12 from broadcast at BroadcastValue.scala:14
2018-06-29 18:02:15 SparkContext: INFO: Starting job: collect at Table.scala:810
2018-06-29 18:02:15 DAGScheduler: INFO: Got job 4 (collect at Table.scala:810) with 1 output partitions
2018-06-29 18:02:15 DAGScheduler: INFO: Final stage: ResultStage 4 (collect at Table.scala:810)
2018-06-29 18:02:15 DAGScheduler: INFO: Parents of final stage: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Missing parents: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting ResultStage 4 (MapPartitionsRDD[27] at mapPartitions at ContextRDD.scala:137), which has no missing parents
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_13 stored as values in memory (estimated size 14.7 KB, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_13_piece0 stored as bytes in memory (estimated size 7.1 KB, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_13_piece0 in memory on 10.1.7.107:62557 (size: 7.1 KB, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[27] at mapPartitions at ContextRDD.scala:137) (first 15 tasks are for partitions Vector(0))
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Adding task set 4.0 with 1 tasks
2018-06-29 18:02:15 TaskSetManager: INFO: Starting task 0.0 in stage 4.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4713 bytes)
2018-06-29 18:02:15 Executor: INFO: Running task 0.0 in stage 4.0 (TID 7)
2018-06-29 18:02:15 BlockManager: INFO: Found block rdd_4_0 locally
2018-06-29 18:02:15 Executor: INFO: Finished task 0.0 in stage 4.0 (TID 7). 1027 bytes result sent to driver
2018-06-29 18:02:15 TaskSetManager: INFO: Finished task 0.0 in stage 4.0 (TID 7) in 14 ms on localhost (executor driver) (1/1)
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-06-29 18:02:15 DAGScheduler: INFO: ResultStage 4 (collect at Table.scala:810) finished in 0.014 s
2018-06-29 18:02:15 DAGScheduler: INFO: Job 4 finished: collect at Table.scala:810, took 0.030550 s
2018-06-29 18:02:15 root: INFO: interpret: PRE-OPT
(TableWrite plotgen/test/test_resources/table.ht overwrite
  (TableParallelize))
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_14 stored as values in memory (estimated size 237.1 KB, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.0 KB, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_14_piece0 in memory on 10.1.7.107:62557 (size: 23.0 KB, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 14 from broadcast at RichContextRDD.scala:20
2018-06-29 18:02:15 SparkContext: INFO: Starting job: collect at ContextRDD.scala:143
2018-06-29 18:02:15 DAGScheduler: INFO: Got job 5 (collect at ContextRDD.scala:143) with 2 output partitions
2018-06-29 18:02:15 DAGScheduler: INFO: Final stage: ResultStage 5 (collect at ContextRDD.scala:143)
2018-06-29 18:02:15 DAGScheduler: INFO: Parents of final stage: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Missing parents: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting ResultStage 5 (MapPartitionsRDD[32] at mapPartitions at ContextRDD.scala:137), which has no missing parents
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_15 stored as values in memory (estimated size 7.2 KB, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.0 KB, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_15_piece0 in memory on 10.1.7.107:62557 (size: 4.0 KB, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[32] at mapPartitions at ContextRDD.scala:137) (first 15 tasks are for partitions Vector(0, 1))
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Adding task set 5.0 with 2 tasks
2018-06-29 18:02:15 TaskSetManager: INFO: Starting task 0.0 in stage 5.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 4931 bytes)
2018-06-29 18:02:15 TaskSetManager: INFO: Starting task 1.0 in stage 5.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 4931 bytes)
2018-06-29 18:02:15 Executor: INFO: Running task 1.0 in stage 5.0 (TID 9)
2018-06-29 18:02:15 Executor: INFO: Running task 0.0 in stage 5.0 (TID 8)
2018-06-29 18:02:15 Executor: INFO: Finished task 1.0 in stage 5.0 (TID 9). 808 bytes result sent to driver
2018-06-29 18:02:15 Executor: INFO: Finished task 0.0 in stage 5.0 (TID 8). 808 bytes result sent to driver
2018-06-29 18:02:15 TaskSetManager: INFO: Finished task 1.0 in stage 5.0 (TID 9) in 30 ms on localhost (executor driver) (1/2)
2018-06-29 18:02:15 TaskSetManager: INFO: Finished task 0.0 in stage 5.0 (TID 8) in 33 ms on localhost (executor driver) (2/2)
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-06-29 18:02:15 DAGScheduler: INFO: ResultStage 5 (collect at ContextRDD.scala:143) finished in 0.034 s
2018-06-29 18:02:15 DAGScheduler: INFO: Job 5 finished: collect at ContextRDD.scala:143, took 0.045593 s
2018-06-29 18:02:15 Hail: INFO: wrote 6 items in 2 partitions
2018-06-29 18:02:15 CodecPool: INFO: Got brand-new decompressor [.gz]
2018-06-29 18:02:15 root: INFO: in Table.value: pre-opt:
(TableRead plotgen/test/test_resources/table.ht)
2018-06-29 18:02:15 root: INFO: in Table.value: post-opt:
(TableRead plotgen/test/test_resources/table.ht)
2018-06-29 18:02:15 CodecPool: INFO: Got brand-new decompressor [.gz]
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C21.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C21.apply instruction count: 18
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C21.apply instruction count: 12
2018-06-29 18:02:15 CodecPool: INFO: Got brand-new decompressor [.gz]
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C22.<init> instruction count: 3
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C22.apply instruction count: 144
2018-06-29 18:02:15 root: INFO: is/hail/codegen/generated/C22.apply instruction count: 12
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_16 stored as values in memory (estimated size 237.1 KB, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.0 KB, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_16_piece0 in memory on 10.1.7.107:62557 (size: 23.0 KB, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 16 from broadcast at HailContext.scala:561
2018-06-29 18:02:15 SparkContext: INFO: Starting job: collect at Table.scala:810
2018-06-29 18:02:15 DAGScheduler: INFO: Got job 6 (collect at Table.scala:810) with 2 output partitions
2018-06-29 18:02:15 DAGScheduler: INFO: Final stage: ResultStage 6 (collect at Table.scala:810)
2018-06-29 18:02:15 DAGScheduler: INFO: Parents of final stage: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Missing parents: List()
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting ResultStage 6 (MapPartitionsRDD[38] at mapPartitions at ContextRDD.scala:137), which has no missing parents
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_17 stored as values in memory (estimated size 9.1 KB, free 4.1 GB)
2018-06-29 18:02:15 MemoryStore: INFO: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.3 KB, free 4.1 GB)
2018-06-29 18:02:15 BlockManagerInfo: INFO: Added broadcast_17_piece0 in memory on 10.1.7.107:62557 (size: 5.3 KB, free: 4.1 GB)
2018-06-29 18:02:15 SparkContext: INFO: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-06-29 18:02:15 DAGScheduler: INFO: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[38] at mapPartitions at ContextRDD.scala:137) (first 15 tasks are for partitions Vector(0, 1))
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Adding task set 6.0 with 2 tasks
2018-06-29 18:02:15 TaskSetManager: INFO: Starting task 0.0 in stage 6.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 4655 bytes)
2018-06-29 18:02:15 TaskSetManager: INFO: Starting task 1.0 in stage 6.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 4655 bytes)
2018-06-29 18:02:15 Executor: INFO: Running task 1.0 in stage 6.0 (TID 11)
2018-06-29 18:02:15 Executor: INFO: Running task 0.0 in stage 6.0 (TID 10)
2018-06-29 18:02:15 Executor: INFO: Finished task 1.0 in stage 6.0 (TID 11). 976 bytes result sent to driver
2018-06-29 18:02:15 Executor: INFO: Finished task 0.0 in stage 6.0 (TID 10). 976 bytes result sent to driver
2018-06-29 18:02:15 TaskSetManager: INFO: Finished task 0.0 in stage 6.0 (TID 10) in 13 ms on localhost (executor driver) (1/2)
2018-06-29 18:02:15 TaskSetManager: INFO: Finished task 1.0 in stage 6.0 (TID 11) in 12 ms on localhost (executor driver) (2/2)
2018-06-29 18:02:15 TaskSchedulerImpl: INFO: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-06-29 18:02:15 DAGScheduler: INFO: ResultStage 6 (collect at Table.scala:810) finished in 0.013 s
2018-06-29 18:02:15 DAGScheduler: INFO: Job 6 finished: collect at Table.scala:810, took 0.028457 s
2018-06-29 18:02:15 SparkContext: INFO: Invoking stop() from shutdown hook
2018-06-29 18:02:15 AbstractConnector: INFO: Stopped Spark@193dc97e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-06-29 18:02:16 SparkUI: INFO: Stopped Spark web UI at http://10.1.7.107:4040
2018-06-29 18:02:16 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2018-06-29 18:02:16 MemoryStore: INFO: MemoryStore cleared
2018-06-29 18:02:16 BlockManager: INFO: BlockManager stopped
2018-06-29 18:02:16 BlockManagerMaster: INFO: BlockManagerMaster stopped
2018-06-29 18:02:16 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2018-06-29 18:02:16 SparkContext: INFO: Successfully stopped SparkContext
2018-06-29 18:02:16 ShutdownHookManager: INFO: Shutdown hook called
2018-06-29 18:02:16 ShutdownHookManager: INFO: Deleting directory /private/var/folders/sb/_knnc68j2tx24w7pqktd64pn5d__pn/T/spark-d716a02b-ce31-4bd6-8279-2a0279f3a9d7
2018-06-29 18:02:16 ShutdownHookManager: INFO: Deleting directory /private/var/folders/sb/_knnc68j2tx24w7pqktd64pn5d__pn/T/spark-d716a02b-ce31-4bd6-8279-2a0279f3a9d7/pyspark-1d43a5dd-ed3d-48fd-b3b8-c8b68eff4ae9
