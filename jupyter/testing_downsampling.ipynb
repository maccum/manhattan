{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "from hail.experimental import ManhattanPreprocessor\n",
    "from hail.experimental import TileGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on Apache Spark version 2.2.0\n",
      "SparkUI available at http://10.1.7.107:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version devel-013c5378964e\n",
      "NOTE: This is a beta version. Interfaces may change\n",
      "  during the beta period. We recommend pulling\n",
      "  the latest changes weekly.\n"
     ]
    }
   ],
   "source": [
    "hl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = {}\n",
    "for i in range(1,23):\n",
    "    if i%2==0:\n",
    "        colors[str(i)] = '#0e6d19'\n",
    "    else:\n",
    "        colors[str(i)] = \"#000000\"\n",
    "colors['X'] = \"#000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-29 17:53:53 Hail: INFO: Reading table with no type imputation\n",
      "  Loading column 'f0' as type 'str' (user-specified)\n",
      "  Loading column 'f1' as type 'int32' (user-specified)\n",
      "  Loading column 'f2' as type 'int32' (user-specified)\n",
      "  Loading column 'f3' as type 'str' (user-specified)\n",
      "  Loading column 'f4' as type 'str' (user-specified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add gene labels\n",
    "mt = hl.read_matrix_table('/Users/maccum/manhattan_data/raw/caffeine_mt')\n",
    "intervals = hl.import_locus_intervals('/Users/maccum/Downloads/genes.37.interval_list')\n",
    "mt = mt.key_rows_by('locus')\n",
    "mt = mt.annotate_rows(gene = intervals[mt.locus].target).key_rows_by('locus','alleles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-29 17:53:54 Hail: INFO: Coerced sorted dataset\n",
      "2018-08-29 17:53:55 Hail: INFO: Coerced sorted dataset\n",
      "2018-08-29 17:53:56 Hail: INFO: Coerced sorted dataset\n",
      "2018-08-29 17:53:56 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2018-08-29 17:53:58 Hail: INFO: Coerced sorted dataset\n",
      "2018-08-29 17:54:00 Hail: INFO: wrote 10879 items in 16 partitions to /Users/maccum/manhattan_data/with_plot_fields/caffeine_mt2\n"
     ]
    }
   ],
   "source": [
    "# add manhattan plotting data to mt\n",
    "#mt = hl.read_matrix_table('/Users/maccum/manhattan_data/raw/caffeine_mt')\n",
    "mp = ManhattanPreprocessor(mt.locus, mt.phenotype, mt.p_value)\n",
    "manhat_mt = mp.add_manhattan_data(colors)\n",
    "manhat_mt.write('/Users/maccum/manhattan_data/with_plot_fields/caffeine_mt2', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoom level: 2 |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "# read manhattan plotting data from disk and start tile generation\n",
    "manhat_mt = hl.read_matrix_table('/Users/maccum/manhattan_data/with_plot_fields/caffeine_mt2')\n",
    "tg = TileGenerator(manhat_mt,\n",
    "                  dest='/Users/maccum/manhattan_data/plots/caffeine_plots_2',\n",
    "                  regen=True,\n",
    "                  x_margin=10000000,\n",
    "                  y_margin=2)\n",
    "\n",
    "tg.generate_tile_layer(phenotype='caffeine_consumption', zoom=2, new_log_file=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "| gp_range.min | gp_range.max |\n",
      "+--------------+--------------+\n",
      "|        int32 |        int64 |\n",
      "+--------------+--------------+\n",
      "|       904164 |   3035120653 |\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "manhat_mt.gp_range.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoom level: 3 |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "tg.generate_tile_layer(phenotype='caffeine_consumption',zoom=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoom level: 3 |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Zoom level: 4 |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Zoom level: 5 |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Zoom level: 6 |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Zoom level: 7 |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Zoom level: 8 |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "tg.generate_tile_layer(phenotype='caffeine_consumption',zoom=3)\n",
    "tg.generate_tile_layer(phenotype='caffeine_consumption',zoom=4)\n",
    "tg.generate_tile_layer(phenotype='caffeine_consumption',zoom=5)\n",
    "tg.generate_tile_layer(phenotype='caffeine_consumption',zoom=6)\n",
    "tg.generate_tile_layer(phenotype='caffeine_consumption',zoom=7)\n",
    "tg.generate_tile_layer(phenotype='caffeine_consumption',zoom=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-----------------+---------+----------------------+\n",
      "| locus         | alleles    | global_position | color   | phenotype            |\n",
      "+---------------+------------+-----------------+---------+----------------------+\n",
      "| locus<GRCh37> | array<str> |           int64 | str     | str                  |\n",
      "+---------------+------------+-----------------+---------+----------------------+\n",
      "| 3:11677077    | [\"C\",\"T\"]  |       504127070 | #000000 | caffeine_consumption |\n",
      "| 3:52099441    | [\"T\",\"C\"]  |       544549434 | #000000 | caffeine_consumption |\n",
      "| 19:47224607   | [\"C\",\"T\"]  |      2706668928 | #000000 | caffeine_consumption |\n",
      "+---------------+------------+-----------------+---------+----------------------+\n",
      "\n",
      "+-------------+-------------+-------------+--------------+\n",
      "|     min_nlp |     max_nlp |     p_value | neg_log_pval |\n",
      "+-------------+-------------+-------------+--------------+\n",
      "|     float64 |     float64 |     float64 |      float64 |\n",
      "+-------------+-------------+-------------+--------------+\n",
      "| 3.03485e-06 | 9.76749e+00 | 2.74879e-04 |  8.19918e+00 |\n",
      "| 3.03485e-06 | 9.76749e+00 | 5.72837e-05 |  9.76749e+00 |\n",
      "| 3.03485e-06 | 9.76749e+00 | 2.21356e-04 |  8.41574e+00 |\n",
      "+-------------+-------------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "manhat_mt.filter_entries(manhat_mt.neg_log_pval > 8).entries().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gp': 1000, 'label': ['foo', 3], 'nlp': 10}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ht = hl.utils.range_table(5)\n",
    "#ht = ht.annotate(y = ht.idx%2, e = \"#00000\", f = hl.str(ht.idx%2==0), alleles=hl.array(['C','T']))\n",
    "#ds = ht.aggregate(hl.agg.downsample(ht.idx, ht.y, [ht['e'], ht['f'], ht['alleles']]))\n",
    "#ds\n",
    "#hl.str(hl.parse_locus('1:100')).value\n",
    "#hl.str(hl.bool(True)).value\n",
    "#hl.str(hl.array(['C','T'])).value\n",
    "label = ['foo', 3]\n",
    "point = {'gp':1000, 'nlp': 10}\n",
    "point['label'] = label\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['C', 'T']\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(hl.array(['C','T']).value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alleles': '[C,T]',\n",
       "  'chrPos': '3:11677077',\n",
       "  'gp': 504127070,\n",
       "  'nlp': 8.19918,\n",
       "  'p': 2.74879},\n",
       " {'alleles': '[T,C]',\n",
       "  'chrPos': '3:52099441',\n",
       "  'gp': 544549434,\n",
       "  'nlp': 9.76749,\n",
       "  'p': 5.72837}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = [\n",
    "    {\n",
    "    'gp': 504127070,\n",
    "    'nlp': 8.19918,\n",
    "    'chrPos': '3:11677077',\n",
    "    'alleles': '[C,T]', \n",
    "    'p': 2.74879\n",
    "    },\n",
    "    {\n",
    "    'gp': 544549434,\n",
    "    'nlp': 9.76749,\n",
    "    'chrPos': \"3:52099441\",\n",
    "    'alleles': '[T,C]', \n",
    "    'p': 5.72837\n",
    "    },\n",
    "]\n",
    "import json\n",
    "with open('test.json', 'w') as outfile:\n",
    "    json.dump(metadata, outfile)\n",
    "    \n",
    "    \n",
    "with open('test.json') as data_file:    \n",
    "    read_metadata = json.load(data_file)\n",
    "read_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'gp_range': struct {\n",
      "        min: int32, \n",
      "        max: int64\n",
      "    } \n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    'phenotype': str \n",
      "    'min_nlp': float64 \n",
      "    'max_nlp': float64 \n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37> \n",
      "    'alleles': array<str> \n",
      "    'global_position': int64 \n",
      "    'color': str \n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'p_value': float64 \n",
      "    'neg_log_pval': float64 \n",
      "----------------------------------------\n",
      "Column key: ['phenotype']\n",
      "Row key: ['locus', 'alleles']\n",
      "Partition key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "manhat_mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-28 17:28:11 Hail: INFO: Reading table with no type imputation\n",
      "  Loading column 'f0' as type 'str' (user-specified)\n",
      "  Loading column 'f1' as type 'int32' (user-specified)\n",
      "  Loading column 'f2' as type 'int32' (user-specified)\n",
      "  Loading column 'f3' as type 'str' (user-specified)\n",
      "  Loading column 'f4' as type 'str' (user-specified)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = hl.array(['locus', 'alleles']).extend(hl.array(['foo', 'bar']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'bar']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[2:].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'd']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['a', 'b', 'c', 'd'][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.99609375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2047/2048)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
